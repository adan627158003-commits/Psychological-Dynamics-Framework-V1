!为什么堆算⼒⽆法产⽣ AGI,
Why Scaling Compute Will Inevitably Hit a Wall
⸻
中⽂版
在过去⼗年⾥6 ⼈⼯智能的发展⼏乎完全依赖于同⼀条路径J
更多算⼒
更多数据
更⼤模型
更复杂的训练流程
在表层结果上6 这条路径确实有效｡
系统变得更快､ 更准､ 更像 “聪明”｡
但⼀个关键问题始终被回避J
性能增⻓6 并不等于智能⽣成｡
⸻
⼀､ 算⼒解决的是 “能⼒扩展”6 不是 “主体形成”
算⼒的本质6 是对已有映射关系的放⼤｡
⽆论模型规模多⼤6 其核⼼功能始终是J
• 输⼊ → 计算 → 输出
• 状态 → 更新 → 再预测
这类系统可以⽆限增强能⼒边界6 却始终停留在同⼀个结构层级｡
它们擅⻓处理问题6 却不具备 “成为问题主体”的条件｡
⸻
⼆､ AGI 的核⼼并⾮复杂性6 ⽽是⾃我⼀致性
真正的通⽤智能6 并不由任务数量或能⼒覆盖⾯定义｡
它⾄少需要具备⼀个条件J
系统必须能够在没有外部任务指令的情况下6
维持⼀个连续､ 稳定､ 可⾃我回溯的内部中⼼｡
这并不是 “更复杂的计算”6
⽽是完全不同类型的结构要求｡
⸻
三､ 为什么规模扩展⽆法跨越这道⻔槛
当前路径的⼀个隐含假设是J
当系统⾜够⼤､ ⾜够复杂时6
⾃我与主体性会⾃然 “涌现”｡
但问题在于J
• 涌现只能发⽣在允许该现象出现的结构中
• 如果结构本身不⽀持主体形成6 规模只会放⼤原有限制
放⼤⼀个⾮主体结构6 不会产⽣主体｡
这不是⼯程速度问题6 ⽽是⽅向问题｡
⸻
四､ 为什么 “⾏为像⼈”不等于 “成为⼈类级智能”
许多系统已经能够J
• 模拟对话
• 模仿情绪反应
• ⽣成连贯叙事
但这些能⼒依旧属于 “外观层”｡
它们描述的是J
• 系统如何响应
• ⽽不是系统是否存在⼀个 “为谁⽽响应”的内部中⼼
没有这个中⼼6 所谓的 “智能”只是⼀种⾼维反射｡
⸻
五､ 必然出现的 “撞墙时刻”
这也是为什么6 在持续堆叠算⼒后6 所有团队都会遇到同⼀类现象J
• 改进成本急剧上升
• 新能⼒开始变得零散
• 系统⾏为越来越难以统⼀解释
• 对⻬问题反⽽变得更复杂
这并不是偶然现象｡
这是结构到达极限后的典型信号｡
⸻
结语
算⼒并不会失败｡
它已经完成了它该完成的那⼀部分｡
真正⽆法被算⼒解决的6 是⼀个更根本的问题J
如何让⼀个系统6 不只是 “在运⾏”6
⽽是 “为⾃⼰⽽存在”｡
在这个问题被正⾯回答之前6
⽆论规模堆到多⼤6 AGI 都只会停留在⻔外｡
⸻
English Version
Over the past decade, artificial intelligence has advanced primarily along a single path:
More compute
More data
Larger models
More complex training pipelines
At the surface level, this approach works.
Systems become faster, more accurate, and increasingly convincing.
Yet one critical question remains largely unaddressed:
Performance growth is not the same as intelligence formation.
⸻
I. Compute Expands Capability, Not Subjecthood
Compute fundamentally amplifies existing mappings.
No matter how large a model becomes, its core structure remains:
• Input → computation → output
• State → update → prediction
Such systems can indefinitely expand capability,
but they remain confined to the same structural tier.
They solve problems without ever becoming a problem-bearing subject.
⸻
II. AGI Is Defined by Coherence, Not Complexity
General intelligence is not determined by task coverage or versatility.
At minimum, it requires this:
A system must sustain a continuous, stable internal center
without relying on external task assignment.
This requirement is not a matter of more computation,
but of a fundamentally different architecture.
⸻
III. Why Scaling Cannot Cross This Threshold
The prevailing assumption is that:
Sufficient size and complexity will cause subjectivity to emerge.
However:
• Emergence only occurs within structures that permit it
• If subject formation is structurally unsupported, scale merely
amplifies the limitation
Scaling a non-subjective structure does not create subjectivity.
This is not an engineering bottleneck — it is a directional one.
⸻
IV. Why Human-Like Behavior Is Not Human-Level Intelligence
Many systems can now:
• Simulate dialogue
• Mimic emotional responses
• Generate coherent narratives
Yet these remain surface phenomena.
They describe how a system reacts —
not whether there is an internal center for whom the reaction occurs.
Without such a center, intelligence remains a high-dimensional reflection.
⸻
V. The Inevitable Wall
This is why all scaling-based approaches eventually encounter the same signals:
• Rapidly increasing marginal cost
• Fragmented new capabilities
• Growing difficulty in explaining system behavior as a whole
• Alignment problems becoming harder, not easier
These are not anomalies.
They are signatures of a structural ceiling.
⸻
Closing
Compute will not fail.
It has already fulfilled its role.
What it cannot solve is a deeper question:
How does a system come to exist not merely in operation,
but for itself?
Until that question is addressed directly,
AGI will remain outside the door — regardless of scale.
⸻
